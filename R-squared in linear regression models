{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5d2bc-bc3d-4eea-9236-fe2996fb9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "#represent?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a7069-c11f-4add-be93-8a743d0084ba",
   "metadata": {},
   "source": [
    "R-squared is a goodness-of-fit measure for linear regression models. \n",
    "It indicates the percentage of the variance in the dependent variable that the independent variables can explain. \n",
    "R-squared measures the strength of the relationship between the model and the dependent variable on a convenient 0 – 100% scale\n",
    "\n",
    "\n",
    "The formula for R-squared is:\n",
    "\n",
    "R-squared = Explained variation / Total variation\n",
    "\n",
    "where Explained variation is the variation in the dependent variable that is explained by the independent variables and Total variation is the total variation in the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4789a-5dd7-4288-92ec-d94f1c54b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce5e70-7cb7-49f0-983a-f2527f33eb12",
   "metadata": {},
   "source": [
    "Adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model. \n",
    "\n",
    "The adjusted R-squared increases when the new term improves the model more than would be expected by chance alone. \n",
    "\n",
    "The difference between adjusted R-squared and R-squared is that adjusted R-squared considers and tests different independent variables against the model and R-squared does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca5154-6814-46ff-91f1-521dfa6ea84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f528dc-43c8-42fc-904c-706d29c063b0",
   "metadata": {},
   "source": [
    "Adjusted R-squared is used when there are multiple variables in the regression model. It allows us to compare models with differing numbers of independent variables. It makes a more accurate view of the correlation between one variable and another than R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6aa13-8a73-4690-bf39-ca19a52dec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "#calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7645e687-925b-439d-b46b-f52b60912e9b",
   "metadata": {},
   "source": [
    "In regression analysis, RMSE (Root Mean Squared Error), MSE (Mean Squared Error), and MAE (Mean Absolute Error) are metrics used to evaluate the performance of regression models\n",
    "\n",
    "MAE represents the difference between the original and predicted values extracted by averaging the absolute difference over the dataset\n",
    "\n",
    "MSE is calculated by taking the average of squared differences between predicted and actual values\n",
    "\n",
    "RMSE is calculated by taking the square root of MSE\n",
    "\n",
    "They are also widely used to evaluate the performance of regression models with other random models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59ef7a0-7860-45f2-98b4-ec2ba8ab712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "#regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cf031-05cf-4d4d-b108-d2fae4050aab",
   "metadata": {},
   "source": [
    "Advantages of RMSE:\n",
    "The output value we get is in the same unit as the required output variable which makes interpretation of loss easy.\n",
    "\n",
    "Disadvantages of RMSE:\n",
    "It is not that robust to outliers as compared to MAE\n",
    "\n",
    "Advantages of MAE:\n",
    "It is more robust to outliers than RMSE\n",
    "It is easier to interpret than RMSE because it doesn’t involve square roots\n",
    "\n",
    "Disadvantages of MAE:\n",
    "It doesn’t punish large errors as much as MSE or RMSE\n",
    "\n",
    "\n",
    "Overall\n",
    "\n",
    "The Mean Squared Error (MSE) and Root Mean Square Error (RMSE) penalize large prediction errors more than Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dde96dc-3c0f-46d6-a39b-8a4c2d4c39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "#it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aad6e4-4230-4642-8d16-57922054f5f6",
   "metadata": {},
   "source": [
    "Lasso and Ridge regularization are both techniques used to prevent overfitting in linear regression models. The main difference between Lasso and Ridge regularization is that Lasso uses L1 regularization while Ridge uses L2 regularization.\n",
    "\n",
    "In general, if we have many features with high correlation and we need to take away the useless features then Lasso is the better solution. \n",
    "\n",
    "If the number of features is greater than the number of observations and many features have multicollinearity, Ridge regularization is a better solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ad4f5-c819-4687-a7f4-7c387a047546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "#example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce81aa-7aee-40f7-a597-abf66107d948",
   "metadata": {},
   "source": [
    "Regularized linear models are used to prevent overfitting in machine learning by adding a penalty term to the cost function of a linear regression model. This penalty term is used to constrain the weights of the model and thus prevent overfitting\n",
    "\n",
    "For example we have a dataset with 100 features and we want to fit a linear regression model. \n",
    "\n",
    "If we use all 100 features, we may end up with an overfitted model, here Regularization can help prevent this by adding a penalty term to the cost function that discourages large weights for each feature. This will force the model to focus on the most important features and ignore the less important ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a503a-06ab-4d2e-94cf-f1a07938d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "#choice for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11c991-eea9-4b29-92f8-624996893eec",
   "metadata": {},
   "source": [
    "Regularized linear models are used for regression analysis because they can help prevent overfitting and improve model performance. \n",
    "\n",
    "However, there are disadvantages as well:\n",
    "\n",
    "Regularization can be too restrictive and lead to underfitting if the regularization parameter is set too high\n",
    "\n",
    "Regularization can be too weak and lead to overfitting if the regularization parameter is set too low\n",
    "\n",
    "Regularization assumes that all variables are equally important, which may not always be true in practice\n",
    "\n",
    "Regularization can be computationally expensive for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49507d9-cf2e-4af4-abd3-03c87c29bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "#Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "#performer, and why? Are there any limitations to your choice of metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a118b1-3328-47e4-b7a5-a92b4a810786",
   "metadata": {},
   "source": [
    "The choice of metric depends on the problem we are trying to solve. \n",
    "\n",
    "RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error) are both used to evaluate regression models. \n",
    "\n",
    "RMSE is more sensitive to outliers than MAE because it squares the errors before averaging them. This means that large errors have a greater impact on RMSE than on MAE.\n",
    "\n",
    "Model B has an MAE of 8 which means that the average error is 8 units away from the actual value. \n",
    "\n",
    "On the other hand, Model A has an RMSE of 10 which means that the average error is 10 units away from the actual value. \n",
    "\n",
    "Since both models have different evaluation metrics, it’s not possible to compare them directly. However, if we want to choose a model based on the evaluation metric alone, then Model B would be a better performer because it has a lower error rate\n",
    "\n",
    "\n",
    "There are limitations to using these metrics. For example, we are told anything about the distribution of errors or whether there are any outliers in the data. Therefore, it’s important to use other methods such as visualizations to get a better understanding of the data and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c5e5ea-ffe4-4fbe-a2ca-b64747c74c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "#regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "#uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "#better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "#method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f63163-51e1-4c38-bf76-e80aa77c70bf",
   "metadata": {},
   "source": [
    "Both Ridge and Lasso regression are regularization techniques that are used to prevent overfitting in linear regression models. Ridge regression adds a penalty term to the sum of squared errors (SSE) that is proportional to the square of the magnitude of the coefficients. Lasso regression adds a penalty term that is proportional to the absolute value of the magnitude of the coefficients\n",
    "\n",
    "\n",
    "The choice between Ridge and Lasso regularization depends on the data and the problem at hand. Ridge regression is better when there are many features with high correlation and we need to take away useless features. Lasso regression is better when there are many features with multicollinearity\n",
    "\n",
    "In terms of performance, it’s difficult to say which model would be better without more information about the data and problem.However, Ridge regression tends to perform better when there are many predictors with small or moderate effect sizes, while Lasso regression tends to perform better when there are only a few predictors with large effect sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfb882-205f-41b0-8b16-fa00ba23ec88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
