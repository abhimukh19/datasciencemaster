{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5751ce-440b-4496-a606-2d3720612648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be80735-82d9-45a4-bafb-d0f804a4f28d",
   "metadata": {},
   "source": [
    "A contingency matrix is a table that is used to evaluate the performance of a classification model. It is also known as a confusion matrix. It is used to evaluate the accuracy of a model by comparing the predicted values with the actual values. The matrix consists of four cells that represent the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN).\n",
    "\n",
    "The contingency matrix can be used to calculate various performance metrics such as accuracy, precision, recall, F1 score, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5513d63-94ef-4893-98f7-1b27adfa3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in\n",
    "#certain situations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b14a4-0c45-4553-9dae-f9e22c20ad4f",
   "metadata": {},
   "source": [
    "A pair confusion matrix is a 2 by 2 similarity matrix that is used to compare two clusterings by considering all pairs of samples and counting pairs that are assigned into the same or into different clusters under the true and predicted clusterings. It is used to evaluate the performance of clustering algorithms. The matrix displays the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2fb334-0bf8-48e3-b964-a2590d451c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically\n",
    "#used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a48fc-e62c-4ec3-bf27-b1309df94d67",
   "metadata": {},
   "source": [
    "An extrinsic measure is a performance metric that is used to evaluate the performance of a natural language processing (NLP) model on a specific task. It is used to evaluate how well the model performs on a real-world task. For example, if we are building a machine translation model, an extrinsic measure would be the accuracy of the translations produced by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f143f065-5bdb-4801-be9c-bf5622164233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an\n",
    "#extrinsic measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0318b55-bbf7-4f03-badf-2dd9141484ca",
   "metadata": {},
   "source": [
    "An intrinsic measure is a performance metric that is used to evaluate the performance of a machine learning model on an intermediary objective (i.e., the performance of a machine learning component on a defined subtask). It is used to evaluate how well the model performs on a specific subtask.\n",
    "\n",
    "\n",
    "Extrinsic measures are different from intrinsic measures, which are used to evaluate the performance of a machine learning model on an intermediary objective (i.e., the performance of a machine learning component on a defined subtask).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d70c31-2e05-444b-a7e7-a2b7a35c2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify\n",
    "#strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b395930e-2c89-4eb5-ad91-4c29eb14a6e0",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is used to evaluate the performance of a classification model. It is used to identify the strengths and weaknesses of a model by comparing the predicted labels to the true labels.\n",
    "\n",
    "The confusion matrix displays the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba08b3d8-aa18-44cb-bf58-dfded60a4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised\n",
    "#learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80510f0-31c4-431f-91c8-f46237ff7ce9",
   "metadata": {},
   "source": [
    "Some common intrinsic measures used to evaluate the performance of unsupervised learning algorithms include:\n",
    "\n",
    "Reconstruction error: This is a measure of how well the algorithm can reconstruct the input data. It is calculated as the difference between the input data and the reconstructed data.\n",
    "\n",
    "Clustering accuracy: This is a measure of how well the algorithm can group similar data points together. It is calculated as the percentage of correctly classified data points.\n",
    "\n",
    "Silhouette score: This is a measure of how well the algorithm can separate different clusters. It is calculated as the difference between the average distance between data points in a cluster and the average distance between data points in different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "277e1ad8-b58b-4aec-b753-1e0786b6767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and\n",
    "#how can these limitations be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae63329-0ffe-49b6-b399-8f2831fe14cd",
   "metadata": {},
   "source": [
    "Imbalanced datasets: If the dataset is imbalanced (i.e., one class has significantly more examples than the other), then accuracy can be misleading\n",
    "\n",
    "Misclassification costs: Different types of misclassifications can have different costs.\n",
    "\n",
    "Multiclass classification: Accuracy can be misleading in multiclass classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b343d-d1c1-4643-8f50-57bace48491f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
