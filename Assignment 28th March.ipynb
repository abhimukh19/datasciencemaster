{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c942a8-8685-4de4-b248-51070ac3c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf83d5-cbcd-4f8d-85ed-361671a3479b",
   "metadata": {},
   "source": [
    "Ridge regression is a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator called ridge estimator that has lower variance than the OLS estimator\n",
    "\n",
    "The ordinary least squares model seeks to find the coefficients that minimize the mean squared error. On the other hand, Ridge Regression tries to find the coefficients that minimize the mean squared error and wants the magnitude of coefficients to be as small as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9ffba-c5d7-4fe1-b0ac-004643bba4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f1562-a725-47dc-9402-aa49ca1b6e42",
   "metadata": {},
   "source": [
    "The assumptions of Ridge Regression are similar to those of Linear Regression. They are:\n",
    "\n",
    "Linear relationship between regression coefficients and dependent variable\n",
    "\n",
    "Mean of errors should be zero\n",
    "\n",
    "Constant variance of error (Heteroscedasticity)\n",
    "\n",
    "No correlation between errors (autocorrelation)\n",
    "\n",
    "No correlation between error and dependent variable\n",
    "\n",
    "Dependent variable should not have 0 variance (0 variance means all dependent variables are same)\n",
    "\n",
    "Normality of Residuals (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26952cd-6eae-4057-8601-647696ed3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478398a1-9970-40fc-9222-77e09961b67f",
   "metadata": {},
   "source": [
    "The tuning parameter lambda in Ridge Regression is chosen by resampling (namely cross-validation). Generally, this is done using cross-validation\n",
    "\n",
    "The value of lambda that produces the lowest possible test MSE (mean squared error) is selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc46fa7-d0ae-407f-b74c-e97a269831e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5986dd3-ca50-454d-a7d8-72eb5b57c174",
   "metadata": {},
   "source": [
    "Yes, Ridge Regression can be used for feature selection. Ridge regression has already performed variable selection (similar to LASSO), that is all variables with coefficients !=0 have an effect. It may happen that some variables have coefficients very close to 0 but not exactly 0, we can threshold these to 0\n",
    "\n",
    "We can use ridge regression for feature selection while fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc939c19-122a-4726-9de5-d068239ca31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6415a62a-e6e2-4188-93b4-e9cbfa5b6cf2",
   "metadata": {},
   "source": [
    "Ridge regression is a model tuning method that is used to analyze any data that suffers from multicollinearity.\n",
    "\n",
    "When the issue of multicollinearity occurs, least-squares are unbiased, and variances are large, this results in predicted values being far away from the actual values. Ridge regression is used for the analysis of multicollinearity in multiple regression data\n",
    "\n",
    "It is most suitable when a data set contains a higher number of predictor variables than the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c5034-767d-439b-b6f4-943afbb4ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199af14-fc97-43ae-b205-671b303ff066",
   "metadata": {},
   "source": [
    "Yes, Ridge Regression can handle both categorical and continuous independent variables. Ridge regression uses a Tikhonov regularized version of the covariance matrix of X.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87fc16e-4aa9-48fb-a42c-36041f21cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0733d-6357-4720-9f6b-a264bfa127ab",
   "metadata": {},
   "source": [
    "In Ridge Regression, the coefficients are penalized such that those that are the least effective in your estimation will “shrink” the fastest. Imagine we have a budget allocated and each coefficient can take some to play a role in the estimation. \n",
    "\n",
    "Naturally, those who are more important will take more of the budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8075a-8ae6-4fb0-9935-ed8c846644fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03793df1-30c8-4b51-9775-4db84f27092c",
   "metadata": {},
   "source": [
    "Yes, Ridge Regression can be used for time-series data analysis. Ridge regression is a popular type of regularized linear regression that includes an L2 penalty. This has the effect of shrinking the coefficients for those input variables that do not contribute much to the prediction task\n",
    "\n",
    "In order to use Ridge Regression for time-series data analysis, we can use a sliding window approach where we train our model on a fixed number of previous time steps and then predict the next time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0de85f-48c1-491e-b3b7-0a2b5f5553d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
