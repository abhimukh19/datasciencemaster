{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7739b5-9ffc-46c0-bb48-aa6ad4195d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "#metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b72cbd-31a7-4169-80da-e4effbb7597b",
   "metadata": {},
   "source": [
    "The main difference between Euclidean distance metric and Manhattan distance metric in KNN is that Euclidean distance measures the shortest distance between two points in a straight line while Manhattan distance measures the distance between two points along the axis at right angles. \n",
    "\n",
    "In other words, Euclidean distance is calculated as the square root of the sum of squared differences between two points while Manhattan distance is calculated as the sum of absolute differences between two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1253118c-0ab3-475d-a1c3-3e771906cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "#used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46152914-e428-4b25-b174-b59715935945",
   "metadata": {},
   "source": [
    "The optimal value of k for a KNN classifier or regressor can be chosen by using an error plot or accuracy plot to find the most favorable k value. The optimal k value usually found is the square root of N, where N is the total number of samples\n",
    "\n",
    "There are different techniques that can be used to determine the optimal k value such as cross-validation, grid search, and elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f928943e-b4c9-4417-82f8-2af591fd410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "#what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc1a4c-282f-467f-947d-98a115e60952",
   "metadata": {},
   "source": [
    "The choice of distance metric can affect the performance of a KNN classifier or regressor1. The performance of KNN classifier depends significantly on the distance used, and there are large gaps between the performances of different distances. \n",
    "\n",
    "The Euclidean distance metric works well when the data is continuous and has no missing values\n",
    "\n",
    "The Manhattan distance metric works well when the data has categorical features or when there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aee19da-cebe-4299-b0e4-a15f4ae8e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "#the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "#model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29923094-7e95-4cc3-82b3-0f71b96a7686",
   "metadata": {},
   "source": [
    "n_neighbors:Increasing this value can lead to a smoother decision boundary, while decreasing it can lead to a more complex boundary.\n",
    "\n",
    "weights: This hyperparameter specifies how to weight the contributions of each neighbor when making a prediction\n",
    "\n",
    "leaf_size: Larger leaf sizes can lead to faster queries but may result in less accurate predictions.\n",
    "\n",
    "p: When p=1, this corresponds to the Manhattan distance metric, while p=2 corresponds to the Euclidean distance metric.\n",
    "\n",
    "\n",
    "To tune these hyperparameters, we can use techniques such as grid search or random search1. Once we have identified the best hyperparameters using these techniques, we can retrain the model on the entire training set using these hyperparameters and evaluate its performance on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c0ed5d-4c23-4e24-b319-c5533d7e4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "#techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e8a20-d97e-4d0d-a96d-a9519e8726ba",
   "metadata": {},
   "source": [
    "The size of the training set can affect the performance of a KNN classifier or regressor in several ways. One way is that as the size of the training set increases, the computational complexity of KNN also increases. This can make it difficult to use KNN with very large training sets. \n",
    "\n",
    "Another way that the size of the training set can affect KNN performance is by making it more difficult to find an optimal value for k\n",
    "\n",
    "To optimize the size of the training set, one technique that can be used is to use cross-validation. Cross-validation involves dividing the data into multiple subsets and then using each subset as a test set while using all other subsets as a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02c482b-c054-488c-ae66-96de80b12895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "#overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26722b-0d69-4ec2-86eb-513967dd5b6c",
   "metadata": {},
   "source": [
    "KNN can be expensive in determining K if the dataset is large.\n",
    "\n",
    "It requires more memory storage than an effective classifier or supervised learning algorithms.\n",
    "\n",
    "In KNN, the prediction phase is slow for a larger dataset.\n",
    "\n",
    "The computation of accurate distances plays a big role in determining the algorithmâ€™s accuracy.\n",
    "\n",
    "#### To overcome these drawbacks and improve the performance of the model:\n",
    "\n",
    "Use dimensionality reduction techniques such as Principal Component Analysis (PCA) or Linear Discriminant Analysis (LDA) to reduce the number of features and improve the performance of KNN.\n",
    "\n",
    "Use an appropriate distance metric such as Euclidean distance or Manhattan distance.\n",
    "\n",
    "Use an appropriate value of K by using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb206d8-c5ab-4f97-a706-6d8b1babec30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
