{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdf1c89-3b8e-42c5-890c-220d416a96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Gradient Boosting Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2f8e0-e632-4a0f-9684-95a0bfd82fdd",
   "metadata": {},
   "source": [
    "Gradient Boosting Regression is a machine learning technique used in regression tasks. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees1. Gradient Boosting Regression is an analytical technique that is designed to explore the relationship between two or more variables (X, and Y). \n",
    "\n",
    "In each stage of Gradient Boosting Regression, a regression tree is fit on the negative gradient of the given loss function. This estimator builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccf8597-a3ba-4d29-811c-56fd3d076a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Implement a simple gradient boosting algorithm from scratch using Python and NumPy. Use a\n",
    "#simple regression problem as an example and train the model on a small dataset. Evaluate the model's\n",
    "#performance using metrics such as mean squared error and R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2baf287f-5c75-4289-a1de-689b8d24eef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "793bb92b-4925-49a8-bcc4-24c8dc6d2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('quality',axis=1)\n",
    "y=df['quality']\n",
    "\n",
    "X_train, X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31f0688-ed6d-45b3-bb8d-5b79ad5a7218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b45fa002-e7d5-4a83-809b-212318d15ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.3637082684317155\n",
      "R-squared: 0.480851314644443\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595fdd06-eede-4a59-9ca5-3912fa2187f1",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) is a measure of how well a regression model fits the data. It is calculated as the average of the squared differences between the predicted and actual values. In this case, the MSE is 0.3646.\n",
    "\n",
    "The R-squared value is a measure of how well the regression model explains the variation in the data. It ranges from 0 to 1, with higher values indicating a better fit. In this case, the R-squared value is 0.4795."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9c69f95-a5ff-4596-ae2a-ca095a5dc8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5860771210634872\n"
     ]
    }
   ],
   "source": [
    "#Q3. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth to\n",
    "#optimise the performance of the model. Use grid search or random search to find the best\n",
    "#hyperparameters\n",
    "\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, criterion='squared_error', max_depth=8, min_samples_split=5, min_samples_leaf=5, max_features=3)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400e7d33-2bf9-4e8c-8354-13fa37e27b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 25, 'max_features': 3, 'max_depth': 20, 'criterion': 'squared_error'}\n",
      "Best Score: 0.3933764529190281\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid = {'n_estimators': [10, 100,200, 300,1000], 'criterion': ['squared_error'], 'max_depth': [5,8,15,20], 'min_samples_split':[5,10,15,20], 'min_samples_leaf':[5,10,15,20,25], 'max_features':[3,5,10,15]}\n",
    "\n",
    "# Fit the grid search object to the training data and obtain the best hyperparameters\n",
    "\n",
    "rad_search = RandomizedSearchCV(model, param_distributions=param_grid)\n",
    "rad_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best hyperparameters: {rad_search.best_params_}\")\n",
    "print(f\"Best Score: {rad_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284b7f58-14b5-483d-9ebd-dae9d523990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What is a weak learner in Gradient Boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a99541-a50e-4ae9-8c4d-df5c3d3bcdb5",
   "metadata": {},
   "source": [
    "A weak learner in Gradient Boosting refers to a simple model that does only slightly better than random chance.Boosting works as weak learners are added to the ensemble iteratively and combined with many other weak learners, they can form a robust ensemble model to make accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45b2408-dbf4-4070-8dc1-4cb553950216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is the intuition behind the Gradient Boosting algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe181b3e-3150-4c6f-b634-84fef7486361",
   "metadata": {},
   "source": [
    "The intuition behind Gradient Boosting algorithm is to repetitively leverage the patterns in residuals and strengthen a model with weak predictions and make it better. Once we reach a stage where residuals do not have any pattern that could be modeled, we can stop modeling residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab26bd1-7ed8-440d-9490-f7acd6a1c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad43dc4-d365-4ca7-b6b4-60c952470e2f",
   "metadata": {},
   "source": [
    "Gradient Boosting algorithm builds an ensemble of weak learners by combining several smaller, simpler models in order to obtain a more accurate prediction than what an individual model would produce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c7523d-374b-4cea-901c-cd665213a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting\n",
    "#algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18c275-1803-4668-8c03-47648b977aba",
   "metadata": {},
   "source": [
    "Build a base model to predict the observations in the training dataset.\n",
    "\n",
    "Calculate the residuals of the base model and fit a new model to these residuals.\n",
    "\n",
    "Repeat step 2 until a stopping criterion is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee932d-4470-489a-8f6b-96dc23a0d61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
