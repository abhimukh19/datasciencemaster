{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc98b30-b374-4f1d-96a2-967b1c1fe9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7244d9e-2f68-4692-84da-3a07617edb6e",
   "metadata": {},
   "source": [
    "GridSearchCV is a function that comes in Scikit-learn’s model_selection package. It is used to perform hyperparameter tuning in order to determine the optimal values for a given model. \n",
    "\n",
    "The performance of a model significantly depends on the value of hyperparameters.A technique for finding the optimal parameter values from a given set of parameters in a grid. It’s essentially a cross-validation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1ca241-86d3-4381-862f-5b192271bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
    "#one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9008f-4e57-458e-9a33-89dc7b42db79",
   "metadata": {},
   "source": [
    "GridSearchCV and RandomizedSearchCV are both hyperparameter optimization techniques used in machine learning to find the best set of hyperparameters for a model. The main difference between them is that GridSearchCV tries every combination of a preset list of values of the hyperparameters and chooses the best combination based on the cross-validation score, while RandomizedSearchCV tries random combinations of a range of values (we have to define the number of iterations) \n",
    "\n",
    "In summary, if we have a small dataset and want to try all possible combinations of hyperparameters, use GridSearchCV. If we have a large dataset and want to try only a few random combinations of hyperparameters, use RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cebcf-da35-491d-aaf0-355d96f1cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7159d8-462c-479c-8ede-6778f9aa9b5b",
   "metadata": {},
   "source": [
    "Data leakage is a problem in machine learning when information from outside the training dataset is used to create the model.\n",
    "\n",
    "Leakage can occur when there is a mistake made by the creator of a machine learning model in which they accidentally share information between the test and training datasets. Leakage can also occur when there is a data contamination between training and testing datasets \n",
    "\n",
    "\n",
    "For example, suppose we are trying to predict whether a customer will buy a product based on their age, gender, and income. If we include information about whether they have already bought the product in our training data, then our model will be able to predict whether someone will buy the product based on whether they have already bought it, which is not useful for predicting future purchases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3869b936-a927-4a39-bf73-6d709ec5c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a5374-7b6f-40f2-88ce-ffbdf09e9a4e",
   "metadata": {},
   "source": [
    "Here are some ways to prevent data leakage when building a machine learning model:\n",
    "\n",
    "Normalizing correctly before cross-validation\n",
    "\n",
    "Splitting dataset\n",
    "\n",
    "Eliminating duplicates\n",
    "\n",
    "Selecting features that are not correlated with the target variable and were available at the time of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fffb23-cb46-4047-8405-6e7bffe96ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be2d701-f723-41f6-a57b-329e28b534ad",
   "metadata": {},
   "source": [
    "A confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. \n",
    "\n",
    "The matrix compares the actual target values with those predicted by the machine learning model. \n",
    "\n",
    "It can be used to evaluate the performance of a classification model through the calculation of performance metrics like accuracy, precision, recall, and F1-score\n",
    "\n",
    "A good model is one which has high TP (True Positive) and TN (True Negative) rates, while low FP (False Positive) and FN (False Negative) rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23e86ba-e98d-470f-9ed0-c5e389560f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1c16f-fb87-455b-acf1-493a82f18b7f",
   "metadata": {},
   "source": [
    "Precision is defined as the ratio of true positives (TP) to the total number of predicted positives (TP + false positives (FP)). It measures how many of the predicted positive cases are actually positive. \n",
    "\n",
    "Recall, on the other hand, is defined as the ratio of true positives (TP) to the total number of actual positives (TP + false negatives (FN)). It measures how many of the actual positive cases are correctly identified by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd09c99-08e2-482e-be07-13402f9c3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47147309-8d19-46dc-88eb-f69d3b8d78f7",
   "metadata": {},
   "source": [
    "A confusion matrix is a summary of prediction results on a classification problem. It shows the ways in which our classification model is confused when it makes predictions and types of errors being made.\n",
    "\n",
    "A good model is one which has high TP (True Positive) and TN (True Negative) rates, while low FP (False Positive) and FN (False Negative) rates\n",
    "In an example of binary classification problem where we want to predict whether a person has a disease or not based on some features such as age, gender, blood pressure, etc\n",
    "\n",
    "TP means the number of true positives, which are the cases where the model predicted that the person has the disease and they actually do have it. \n",
    "\n",
    "FN means the number of false negatives, which are the cases where the model predicted that the person does not have the disease but they actually do have it. \n",
    "\n",
    "\n",
    "FP means the number of false positives, which are the cases where the model predicted that the person has the disease but they actually do not have it. \n",
    "\n",
    "TN means the number of true negatives, which are the cases where the model predicted that the person does not have the disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818a4cf1-d0ef-43ee-9d1d-9bb3f119c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
    "#calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec5842-5c5f-4e09-bd1a-44dbabe07bd1",
   "metadata": {},
   "source": [
    "The four main important metrics that can be derived from the confusion matrix are precision, recall, accuracy, and F1 scores.\n",
    "\n",
    "Precision is defined as the number of true positives divided by the number of true positives plus false positives.\n",
    "\n",
    "Recall is defined as the number of true positives divided by the number of true positives plus false negatives.\n",
    "\n",
    "Accuracy is defined as the number of correct predictions divided by the total number of predictions.\n",
    "\n",
    "F1 score is defined as the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6df9e9-0b7b-4897-a13c-4e2f7331b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a2f27-6ffc-4426-9120-0db5af98614d",
   "metadata": {},
   "source": [
    "Accuracy is used to measure the performance of a model. It is the ratio of Total correct instances to the total instances. \n",
    "\n",
    "\n",
    "Accuracy is defined as the number of correct predictions divided by the total number of predictions, these values can be derived out of confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b563ec1-c5ad-4206-abec-c1a76697742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
    "#model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6391523b-167e-4cdb-a5bb-0eb9f2563ee1",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model on a set of data for which the true values are known. \n",
    "\n",
    "It compares the actual target values with those predicted by the machine learning model. \n",
    "\n",
    "The matrix can be used to identify potential biases or limitations in our machine learning model. An asymmetric confusion matrix can reveal a biased classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
